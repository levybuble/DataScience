{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": " # CapstoneCapstone Project - The Battle of the Neighborhoods\n### Applied Data Science Capstone by IBM/Coursera"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Introduction: Business Problem"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Analysis of a locality based on the various venues available in that locality in give useful insights into the kind of Business thriving in that area. This profiling can be used to come up with the type of business which is likely to succeed in that locality.\n\nThis projects aims at profiling the neighborhoods to come up with the best location for starting a new restaurant. The project aims to analyze the localities of New York and Toronto. This will involve profiling these neighborhoods. The profiling will be based on the number and category of venues of various types present in an area. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "New York and Toronto are the two cities which are planned to be analyzed as part of this assignment.\n\nNew York data was provided as part of the previous assignment in the course.\n\nInformation of the neighborhoods names of Toronto will be extracted from Wikipedia article as was done in assignment in week 3.\n\nCoordinates will be extracted using the Geocoder API, which will then be used as input for Foursquare to obtain venue information and map generation."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Methodology\n\nStage 1 - Business Understanding\nAs stated in the previous section of this report, our main goal is to create a reliable profile of the neighborhoods in New York City and Toronto. Our fictional business sponsors are two entrepreneurs, one looking to open a new restaurant in New York City and another one looking to open a new bar in Toronto.\n\nStage 2 - Analytic Approach\nTo decide the ideal neighborhood for the new business, we must classify the neighborhoods into three main different kinds of regions based on the proportion of venue categories present in each one: \na)  Residential\nb) Services\nc) \"Going Out\"\nAfter the necessary data preparation (collection, encoding and normalization) the neighborhoods will be clustered into three groups using the k-means clustering algorithm. To solve our business problem, the third cluster \"Going Out\" will be further studied, and the venue categories in these neighborhoods in this group will be expanded, to give insight in the kinds of places that do not already exist in these neighborhoods. The information can help our business sponsors decide what kind of restaurant or bar are lacking and are probable business opportunities.\n\nStage 3 - Data Requirements\nAs stated in the Data & Tools section, the data requirements for this research are the venue information for each neighborhood in Toronto and New York City. Consequently, information about the neighborhoods (names and geographical coordinates) are also necessary.\n\nStage 4 & 5 - Data Collection & Understanding\nThe required data is collected in the first parts of the Jupyter Notebook. Toronto boroughs and neighborhoods are scrapped from the wikipedia link, using the BeautifulSoup package, and the New York City boroughs and neighborhoods information is scrapped from the JSON file. At this point the data is organized in a Pandas DataFrame like the following:\n"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting folium\n  Downloading folium-0.11.0-py2.py3-none-any.whl (93 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 93 kB 3.6 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from folium) (2.24.0)\nCollecting branca>=0.3.0\n  Downloading branca-0.4.1-py3-none-any.whl (24 kB)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from folium) (1.18.5)\nRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from folium) (2.11.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->folium) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->folium) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->folium) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->folium) (1.25.9)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jinja2>=2.9->folium) (1.1.1)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.4.1 folium-0.11.0\nCollecting geocoder\n  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 98 kB 9.2 MB/s  eta 0:00:01\n\u001b[?25hCollecting ratelim\n  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\nRequirement already satisfied: click in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from geocoder) (7.1.2)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from geocoder) (1.15.0)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from geocoder) (2.24.0)\nRequirement already satisfied: future in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from geocoder) (0.18.2)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ratelim->geocoder) (4.4.2)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->geocoder) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->geocoder) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->geocoder) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->geocoder) (3.0.4)\nInstalling collected packages: ratelim, geocoder\nSuccessfully installed geocoder-1.38.1 ratelim-0.1.6\n"
                }
            ],
            "source": "# library to handle data in a vectorized manner\nimport numpy as np \n\n# library for data analsysis\nimport pandas as pd\nfrom scipy import stats\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# library to handle JSON files\nimport json\n\n# tranform JSON file into a pandas dataframe\nfrom pandas.io.json import json_normalize\n\n# useful time functions library\nimport time\n\n# library to handle requests\nimport requests\n\n# matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\n\n# seaborn and associated plotting modules\nimport seaborn as sns\n\n# plotly and associated plotting modules\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n# map rendering library\n!pip install folium\nimport folium\n\n# import beautifulsoup for html data scrapping\nfrom bs4 import BeautifulSoup\n\n# import geocoder and geopy for geographic coordinates extraction\n!pip install geocoder\nimport geocoder\nfrom geopy.extra.rate_limiter import RateLimiter\nfrom geopy.geocoders import Nominatim "
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting cufflinks\n  Downloading cufflinks-0.17.3.tar.gz (81 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81 kB 10.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.9.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (1.18.5)\nRequirement already satisfied: pandas>=0.19.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (1.0.5)\nRequirement already satisfied: plotly>=4.1.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (4.8.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (1.15.0)\nCollecting colorlover>=0.2.1\n  Downloading colorlover-0.3.0-py3-none-any.whl (8.9 kB)\nRequirement already satisfied: setuptools>=34.4.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (47.3.1.post20200622)\nRequirement already satisfied: ipython>=5.3.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (7.15.0)\nRequirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cufflinks) (7.5.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas>=0.19.2->cufflinks) (2020.1)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas>=0.19.2->cufflinks) (2.8.1)\nRequirement already satisfied: retrying>=1.3.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from plotly>=4.1.1->cufflinks) (1.3.3)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.2.0)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.8.0)\nRequirement already satisfied: jedi>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.17.1)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.4.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (3.0.5)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.3.3)\nRequirement already satisfied: pygments in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (2.6.1)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (3.5.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (5.3.0)\nRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (5.0.7)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.3.0->cufflinks) (0.6.0)\nRequirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.3.0->cufflinks) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks) (0.2.4)\nRequirement already satisfied: ipython-genutils in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=5.3.0->cufflinks) (0.2.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (6.0.3)\nRequirement already satisfied: jupyter-client in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.1.3)\nRequirement already satisfied: tornado>=4.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.0.4)\nRequirement already satisfied: jupyter-core in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (4.6.3)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.2.0)\nRequirement already satisfied: prometheus-client in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.0)\nRequirement already satisfied: terminado>=0.8.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.3)\nRequirement already satisfied: pyzmq>=17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (19.0.1)\nRequirement already satisfied: nbconvert in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (5.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.11.2)\nRequirement already satisfied: Send2Trash in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.5.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (1.6.1)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (19.3.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (0.16.0)\nRequirement already satisfied: bleach in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (3.1.5)\nRequirement already satisfied: defusedxml in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.6.0)\nRequirement already satisfied: testpath in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.4.4)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.3)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.4.2)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.1.0)\nRequirement already satisfied: webencodings in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (20.4)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.4.7)\nBuilding wheels for collected packages: cufflinks\n  Building wheel for cufflinks (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cufflinks: filename=cufflinks-0.17.3-py3-none-any.whl size=67921 sha256=4b51f7a17f3ca23aeb0634fe5f196074b9f2b18888b98ba99458f7bf13910b0f\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/e1/27/13/3fe67fa7ea7be444b831d117220b3b586b872c9acd4df480d0\nSuccessfully built cufflinks\nInstalling collected packages: colorlover, cufflinks\nSuccessfully installed colorlover-0.3.0 cufflinks-0.17.3\n"
                }
            ],
            "source": "!pip install cufflinks"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "import cufflinks as cf"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# Write your google geocoder credentials in the variable below\nGEOCODER_GOOGLE_KEY = 'AIzaSyBbp8Y2IrKTiL0g4Y4ccGI2xLdy0sHK5rw'"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting chart-studio\n  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 64 kB 5.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (1.3.3)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (1.15.0)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (2.24.0)\nRequirement already satisfied: plotly in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (4.8.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (2.9)\nInstalling collected packages: chart-studio\nSuccessfully installed chart-studio-1.1.0\n"
                }
            ],
            "source": "!pip install chart-studio"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "import plotly\nimport plotly.tools"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "# Write your Plotly credentials in the function below\n#py.tools.set_credentials_file(username='levybuble', api_key='\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022')\nimport chart_studio\nchart_studio.tools.set_credentials_file(username='levybuble', api_key='\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022')"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "# Write your Foursquare credentials in the variables below\nCLIENT_ID = 'GEWQ4DJCOSB3YXXH1JDFZ4VCTK2L4QP04MF3CDKL2AZKUXRJ' # your Foursquare ID\nCLIENT_SECRET = '2FPRWMVAASRVAUWRDQOVAW3PQQJ4FCVJTRZPFPONHJ5LQLCB' # your Foursquare Secret\nVERSION = '20180323' # Foursquare API version"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# JSON file downloaded from link https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json\nimport requests\nimport io\nfrom io import StringIO\nimport json\nfrom pandas.io.json import json_normalize\nimport pandas as pd\n\nurl = 'https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json'\nr = requests.get(url=url, headers={'Accept': 'application/json'})\nnewyork_data = json.loads(r.content)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Pandas DataFrame populated with New York City data.\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>301</th>\n      <td>Manhattan</td>\n      <td>Hudson Yards</td>\n      <td>40.756658</td>\n      <td>-74.000111</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>Queens</td>\n      <td>Hammels</td>\n      <td>40.587338</td>\n      <td>-73.805530</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>Queens</td>\n      <td>Bayswater</td>\n      <td>40.611322</td>\n      <td>-73.765968</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>Queens</td>\n      <td>Queensbridge</td>\n      <td>40.756091</td>\n      <td>-73.945631</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>Staten Island</td>\n      <td>Fox Hills</td>\n      <td>40.617311</td>\n      <td>-74.081740</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "           Borough  Neighborhood   Latitude  Longitude\n301      Manhattan  Hudson Yards  40.756658 -74.000111\n302         Queens       Hammels  40.587338 -73.805530\n303         Queens     Bayswater  40.611322 -73.765968\n304         Queens  Queensbridge  40.756091 -73.945631\n305  Staten Island     Fox Hills  40.617311 -74.081740"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Create empty new york data pandas DataFrame\nny_neighborhoods = pd.DataFrame(columns=['Borough', 'Neighborhood', 'Latitude', 'Longitude'])\n\n# Populate ny_neighborhoods_df with new york imported json data\nfor data in newyork_data['features']:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    ny_neighborhoods = ny_neighborhoods.append({'Borough': borough,\n                                                'Neighborhood': neighborhood_name,\n                                                'Latitude': neighborhood_lat,\n                                                'Longitude': neighborhood_lon}, \n                                                ignore_index=True)\nprint('Pandas DataFrame populated with New York City data.')\n\n# Export data do csv file\nny_neighborhoods.to_csv('ny_neighborhoods.csv', sep=',', encoding='utf-8')\n\nny_neighborhoods.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>301</th>\n      <td>Manhattan</td>\n      <td>Hudson Yards</td>\n      <td>40.756658</td>\n      <td>-74.000111</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>Queens</td>\n      <td>Hammels</td>\n      <td>40.587338</td>\n      <td>-73.805530</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>Queens</td>\n      <td>Bayswater</td>\n      <td>40.611322</td>\n      <td>-73.765968</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>Queens</td>\n      <td>Queensbridge</td>\n      <td>40.756091</td>\n      <td>-73.945631</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>Staten Island</td>\n      <td>Fox Hills</td>\n      <td>40.617311</td>\n      <td>-74.081740</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "           Borough  Neighborhood   Latitude  Longitude\n301      Manhattan  Hudson Yards  40.756658 -74.000111\n302         Queens       Hammels  40.587338 -73.805530\n303         Queens     Bayswater  40.611322 -73.765968\n304         Queens  Queensbridge  40.756091 -73.945631\n305  Staten Island     Fox Hills  40.617311 -74.081740"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Alternatively, import data directly from local .csv file prepared\n\ncolnames = ['Borough', 'Neighborhood', 'Latitude', 'Longitude']\nny_neighborhoods = pd.read_csv('ny_neighborhoods.csv', skiprows=1, names=colnames)\nny_neighborhoods.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "# Scrap Toronto Data from Wikipedia\nsource = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n\n# Create BeautifulSoup object\nsoup = BeautifulSoup(source, \"html.parser\")\n\n# Scrap wikipedia HTML data using BeautifulSoup\nwiki_table = soup.find('table', {'class':'wikitable sortable'})\nwiki_table_rows = wiki_table.findAll('tr')\nres = []\n\n# Get boroughs and neighborhoods names from wikipedia table\nfor tr in wiki_table_rows:\n    td = tr.find_all('td')\n    row = [tr.text.strip() for tr in td if tr.text.strip()]\n    if row:\n        if (row[1]!='Not assigned'):\n            if (row[2]=='Not assigned'):\n                row[2]=row[1]\n            res.append(row)\n#print (res)\npost_df = pd.DataFrame(res, columns = [\"PostalCode\", \"Borough\", \"Neighborhood\"])\npost_df = df.groupby([\"PostalCode\", \"Borough\"])[\"Neighborhood\"].apply(\", \".join).reset_index()\n#df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import geocoder\n\ndef get_geocoder(postal_code_from_df):\n     # initialize your variable to None\n     lat_lng_coords = None\n     # loop until you get the coordinates\n     while(lat_lng_coords is None):\n       g = geocoder.google('{}, Toronto, Ontario'.format(postal_code_from_df), key=GEOCODER_GOOGLE_KEY)\n       lat_lng_coords = g.latlng\n     latitude = lat_lng_coords[0]\n     longitude = lat_lng_coords[1]\n     return latitude,longitude\n\nfor i in range(0,(len(post_df['PostalCode']))):\n    post_df.iloc[i]['Latitude'],post_df.iloc[i]['Longitude']=get_geocoder(post_df.iloc[i]['PostalCode'])"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Importing Toronto neighborhoods geographical coordinates using geocoder...\n"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-28-8ce1fd099933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlat_lng_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_lng_coords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}, Toronto, Ontario'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGEOCODER_GOOGLE_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlat_lng_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatlng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/api.py\u001b[0m in \u001b[0;36mgoogle\u001b[0;34m(location, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;34m>\u001b[0m \u001b[0melevation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(location, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid method\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, location, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# query and parse results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/base.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# query URL and get valid JSON (also stored in self.json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;31m# catch errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/base.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/geocoder/google.py\u001b[0m in \u001b[0;36mrate_limited_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limited_get_for_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limited_get_for_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mratelim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<decorator-gen-128>\u001b[0m in \u001b[0;36mrate_limited_get_for_dev\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/ratelim/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtime_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_delta\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__time_interval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__time_interval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_delta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__numcalls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__last_reset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": "# Iterate through 'res' array and find coordinates for each row (borough)\nimport geocoder\nprint('Importing Toronto neighborhoods geographical coordinates using geocoder...')\nfor j in range(0, len(res)):\n    # send request\n    lat_lng_coords = None\n    while(lat_lng_coords is None):\n        g = geocoder.google('{}, Toronto, Ontario'.format(res[j][0]), key=GEOCODER_GOOGLE_KEY)\n        lat_lng_coords = g.latlng\n        \n    #g = geocoder.google('Toronto, Ontario', key=GEOCODER_GOOGLE_KEY)\n    #lat_lng_coords = g.latlng\n    \n    # append coordinates to 'res' array\n    res[j].append(lat_lng_coords[0])\n    res[j].append(lat_lng_coords[1])\n    \n# Populate to_neighborhoods_df with toronto scrapped data from wikipedia\n#to_neighborhoods = pd.DataFrame(res, columns=[\"Postcode\", \"Borough\", \"Neighborhood\", \"Latitude\", \"Longitude\"])\n# Drop \"Postcode\" column\n#to_neighborhoods = to_neighborhoods.drop(columns='Postcode')\n# Print alert\n#print('Pandas DataFrame populated with Toronto data.')\n# Export data to local .csv file\n#to_neighborhoods.to_csv('to_neighborhoods.csv', sep=',', encoding='utf-8')\n#to_neighborhoods.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def generate_map_of_city_boroughs_data(city_name, city_neighborhoods):\n    \n    # Find city geographical coordinates using geocode google API\n    from geopy.geocoders import Nominatim\n    from geopy.exc import GeopyError\n\n    address = city_name\n    if address:\n        geolocator = Nominatim(user_agent=\"my-application\")\n        try:\n            location = geolocator.geocode(address)\n            lat_long = {\n                \"type\": \"Point\",\n                \"coordinates\": [location.longitude, location.latitude]\n            }\n        except (GeopyError, AttributeError):\n            pass\n\n    city_latitude = lat_long['coordinates'][1]\n    city_longitude = lat_long['coordinates'][0]\n    print('The geographical coordinates of \"{}\" are {}, {}.'.format(city_name, city_latitude, city_longitude))\n    \n    # Check number of Boroughs and Neighborhoods in the collected Dataset\n    print('The \"{}\" dataframe has {} boroughs and {} neighborhoods.'.format(\n          city_name,\n          len(city_neighborhoods['Borough'].unique()),\n          len(city_neighborhoods['Neighborhood'].unique())))\n    #############################\n    # create map of city using latitude and longitude values\n    map_city = folium.Map(location=[city_latitude, city_longitude], zoom_start=10)\n    \n   \n    fg=folium.FeatureGroup(name=\"My_Map\")\n\n    for lat, lng, borough, neighborhood in zip(city_neighborhoods['Latitude'], city_neighborhoods['Longitude'], city_neighborhoods['Borough'], city_neighborhoods['Neighborhood']):\n        #print(lat, lng, borough, neighborhood)\n        \n        borough = borough.replace(\"'\", \"&#39;\")\n        neighborhood = neighborhood.replace(\"-\", \"&#39;\")\n        neighborhood = neighborhood.replace(\"'\", \"&#39;\")\n        #label = borough+', '+neighborhood\n        #label = '{}, {}'.format(neighborhood, borough)\n        #print (label)\n        \n        label1 = folium.Popup(borough+', '+neighborhood, parse_html=True)\n        fg.add_child(folium.CircleMarker(\n        location = [lat, lng],\n        radius=5,\n        popup=label1,\n        fill_color='#3186cc',\n        color='blue',\n        fill=True,\n        fill_opacity=0.7))\n    map_city.add_child(fg)\n    display(map_city)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_boroughs_data('New York City, NY', ny_neighborhoods)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_boroughs_data('Toronto, ON', to_neighborhoods)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# getNearbyVenues() is a function made to get the top venues that are in each neighborhood within a radius of X meters\ndef getNearbyVenues(names, latitudes, longitudes, limit=200, radius=1000):\n    \n    venues_list=[]\n    j = 0\n    \n    for name, lat, lng in zip(names, latitudes, longitudes):\n        \n         # print progress\n        if (j == int(0.1*(len(names)-1))):\n            print('Foursquare loop 10% Complete.')\n        if (j == int(0.2*(len(names)-1))):\n            print('Foursquare loop 20% Complete.')\n        if (j == int(0.3*(len(names)-1))):\n            print('Foursquare loop 30% Complete.')\n        if (j == int(0.4*(len(names)-1))):\n            print('Foursquare loop 40% Complete.')\n        if (j == int(0.5*(len(names)-1))):\n            print('Foursquare loop 50% Complete.')\n        if (j == int(0.6*(len(names)-1))):\n            print('Foursquare loop 60% Complete.')\n        if (j == int(0.7*(len(names)-1))):\n            print('Foursquare loop 70% Complete.')\n        if (j == int(0.8*(len(names)-1))):\n            print('Foursquare loop 80% Complete.')\n        if (j == int(0.9*(len(names)-1))):\n            print('Foursquare loop 90% Complete.')\n        if (j == int((len(names)-1))):\n            print('Foursquare loop 100% Complete.')\n        \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            limit)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n        j=j+1\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                             'Neighborhood Latitude', \n                             'Neighborhood Longitude', \n                             'Venue', \n                             'Venue Latitude', \n                             'Venue Longitude', \n                             'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('Importing Toronto neighborhoods nearby venues using Foursquare...')\n# Get data from Foursquare\nto_venues = getNearbyVenues(names=to_neighborhoods['Neighborhood'],\n                            latitudes=to_neighborhoods['Latitude'],\n                            longitudes=to_neighborhoods['Longitude'],\n                            limit=200)\n\nprint('The \"to_venues\" dataframe has {} venues and {} unique venue types.'.format(\n      len(to_venues['Venue Category']),\n      len(to_venues['Venue Category'].unique())))\nto_venues.to_csv('to_venues.csv', sep=',', encoding='UTF8')\nto_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def generate_map_of_city_venues_data(city_name, city_neighborhoods):\n    \n    # Find city geographical coordinates using geocode google API\n    geolocator = Nominatim(user_agent=\"my_jupyter_notebook\")\n    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n    city_location = geolocator.geocode(city_name) #'New York City, NY'\n    city_latitude = city_location.latitude\n    city_longitude = city_location.longitude\n    print('The geographical coordinates of \"{}\" are {}, {}.'.format(city_name, city_latitude, city_longitude))\n    \n    # Check number of Boroughs and Neighborhoods in the collected Dataset\n    print('The \"{}\" dataframe has {} different venue types and {} neighborhoods.'.format(\n          city_name,\n          len(city_neighborhoods['Venue Category'].unique()),\n          len(city_neighborhoods['Neighborhood'].unique())))\n    \n    # create map of city using latitude and longitude values\n    map_city = folium.Map(location=[city_latitude, city_longitude], zoom_start=10)\n\n    # add markers to map\n    for lat, lng, venue, category in zip(city_neighborhoods['Venue Latitude'], city_neighborhoods['Venue Longitude'], city_neighborhoods['Venue'], city_neighborhoods['Venue Category']):\n        label = '{}, {}'.format(category, venue)\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker(\n            [lat, lng],\n            radius=0.1,\n            popup=label,\n            color='red',\n            fill=True,\n            fill_color='#FF0000',\n            fill_opacity=0.3).add_to(map_city)  \n\n    return map_city"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_venues_data('Toronto, ON', to_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_venues_data('New York City, NY', ny_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\"\"\" # Code used to extract all unique venue categories in New York City\n# Save unique categories list as a .csv file\n# format as a block of csv text to do whatever you want\ncsv_rows = [\"{}\".format(i) for i in ny_venues['Venue Category'].unique()]\ncsv_text = \"\\n\".join(csv_rows)\n\n# write it to a file\nwith open('ny_unique_venues.csv', 'w') as f:\n    f.write(csv_text)\n\"\"\"\n\n# Import the manually prepared data extracted with the code above\n# encoding='latin1', encoding='iso-8859-1' or encoding='cp1252'\ncolnames = ['BAR_CLUB', 'RESTAURANT', 'SERVICES', 'LEISURE_SPORTS', 'CULTURAL_SCHOOLS', 'PARKS_NATURE_RURAL', 'TRANSPORT_INFRASTRUCTURE', 'RESIDENTIAL']\nto_unique_venues = pd.read_csv('to_unique_venues.csv', skiprows=1, names=colnames, encoding='latin1')\n\n# Export columns to python lists\nto_BAR_CLUB = to_unique_venues.BAR_CLUB.tolist()\nto_BAR_CLUB = [x for x in to_BAR_CLUB if str(x) != 'nan']\n\nto_RESTAURANT = to_unique_venues.RESTAURANT.tolist()\nto_RESTAURANT = [x for x in to_RESTAURANT if str(x) != 'nan']\n\nto_SERVICES = to_unique_venues.SERVICES.tolist()\nto_SERVICES = [x for x in to_SERVICES if str(x) != 'nan']\n\nto_LEISURE_SPORTS = to_unique_venues.LEISURE_SPORTS.tolist()\nto_LEISURE_SPORTS = [x for x in to_LEISURE_SPORTS if str(x) != 'nan']\n\nto_CULTURAL_SCHOOLS = to_unique_venues.CULTURAL_SCHOOLS.tolist()\nto_CULTURAL_SCHOOLS = [x for x in to_CULTURAL_SCHOOLS if str(x) != 'nan']\n\nto_PARKS_NATURE_RURAL = to_unique_venues.PARKS_NATURE_RURAL.tolist()\nto_PARKS_NATURE_RURAL = [x for x in to_PARKS_NATURE_RURAL if str(x) != 'nan']\n\nto_TRANSPORT_INFRASTRUCTURE = to_unique_venues.TRANSPORT_INFRASTRUCTURE.tolist()\nto_TRANSPORT_INFRASTRUCTURE = [x for x in to_TRANSPORT_INFRASTRUCTURE if str(x) != 'nan']\n\nto_RESIDENTIAL = to_unique_venues.RESIDENTIAL.tolist()\nto_RESIDENTIAL = [x for x in to_RESIDENTIAL if str(x) != 'nan']\n\nto_unique_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_info.append([\"Bars and Clubs\", len(to_BAR_CLUB)])\nto_info.append([\"Restaurants\", len(to_RESTAURANT)])\nto_info.append([\"Services\", len(to_SERVICES)])\nto_info.append([\"Leisure and Sports\", len(to_LEISURE_SPORTS)])\nto_info.append([\"Education and Culture\", len(to_CULTURAL_SCHOOLS)])\nto_info.append([\"Nature and Parks\", len(to_PARKS_NATURE_RURAL)])\nto_info.append([\"Transportation\", len(to_TRANSPORT_INFRASTRUCTURE)])\nto_info.append([\"Residential\", len(to_RESIDENTIAL)])\n\nto_venues_info = pd.DataFrame(to_info, columns=[\"Category\", \"Unique Sub-Categories\"])\nto_venues_info"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\"\"\" # Code used to extract all unique venue categories in Toronto\n# Save unique categories list as a .csv file\n# format as a block of csv text to do whatever you want\ncsv_rows = [\"{}\".format(i) for i in to_venues['Venue Category'].unique()]\ncsv_text = \"\\n\".join(csv_rows)\n\n# write it to a file\nwith open('to_unique_venues.csv', 'w') as f:\n    f.write(csv_text)\n\"\"\"\n\n# Import the manually prepared data extracted with the code above\n# encoding='latin1', encoding='iso-8859-1' or encoding='cp1252'\ncolnames = ['BAR_CLUB', 'RESTAURANT', 'SERVICES', 'LEISURE_SPORTS', 'CULTURAL_SCHOOLS', 'PARKS_NATURE_RURAL', 'TRANSPORT_INFRASTRUCTURE', 'RESIDENTIAL']\nny_unique_venues = pd.read_csv('ny_unique_venues.csv', skiprows=1, names=colnames, encoding='latin1')\n\n# Export columns to python lists\nny_BAR_CLUB = ny_unique_venues.BAR_CLUB.tolist()\nny_BAR_CLUB = [x for x in ny_BAR_CLUB if str(x) != 'nan']\n\nny_RESTAURANT = ny_unique_venues.RESTAURANT.tolist()\nny_RESTAURANT = [x for x in ny_RESTAURANT if str(x) != 'nan']\n\nny_SERVICES = ny_unique_venues.SERVICES.tolist()\nny_SERVICES = [x for x in ny_SERVICES if str(x) != 'nan']\n\nny_LEISURE_SPORTS = ny_unique_venues.LEISURE_SPORTS.tolist()\nny_LEISURE_SPORTS = [x for x in ny_LEISURE_SPORTS if str(x) != 'nan']\n\nny_CULTURAL_SCHOOLS = ny_unique_venues.CULTURAL_SCHOOLS.tolist()\nny_CULTURAL_SCHOOLS = [x for x in ny_CULTURAL_SCHOOLS if str(x) != 'nan']\n\nny_PARKS_NATURE_RURAL = ny_unique_venues.PARKS_NATURE_RURAL.tolist()\nny_PARKS_NATURE_RURAL = [x for x in ny_PARKS_NATURE_RURAL if str(x) != 'nan']\n\nny_TRANSPORT_INFRASTRUCTURE = ny_unique_venues.TRANSPORT_INFRASTRUCTURE.tolist()\nny_TRANSPORT_INFRASTRUCTURE = [x for x in ny_TRANSPORT_INFRASTRUCTURE if str(x) != 'nan']\n\nny_RESIDENTIAL = ny_unique_venues.RESIDENTIAL.tolist()\nny_RESIDENTIAL = [x for x in ny_RESIDENTIAL if str(x) != 'nan']\n\nny_unique_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_info = []\nny_info.append([\"Bars and Clubs\", len(ny_BAR_CLUB)])\nny_info.append([\"Restaurants\", len(ny_RESTAURANT)])\nny_info.append([\"Services\", len(ny_SERVICES)])\nny_info.append([\"Leisure and Sports\", len(ny_LEISURE_SPORTS)])\nny_info.append([\"Education and Culture\", len(ny_CULTURAL_SCHOOLS)])\nny_info.append([\"Nature and Parks\", len(ny_PARKS_NATURE_RURAL)])\nny_info.append([\"Transportation\", len(ny_TRANSPORT_INFRASTRUCTURE)])\nny_info.append([\"Residential\", len(ny_RESIDENTIAL)])\n\nny_venues_info = pd.DataFrame(ny_info, columns=[\"Category\", \"Unique Sub-Categories\"])\nny_venues_info"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace1 = go.Bar(x=to_venues_info['Category'],\n                y=to_venues_info['Unique Sub-Categories'],\n                opacity=0.3,\n                name=\"Unique Sub-Categories in Toronto\")\ntrace2 = go.Bar(x=ny_venues_info['Category'],\n                y=ny_venues_info['Unique Sub-Categories'],\n                opacity=0.3,\n                name=\"Unique Sub-Categories in New York City\")\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='overlay')\nfig = go.Figure(data=data, layout=layout)\n\npy.plotly.iplot(fig)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def encode_venues_categories(dataframe):\n    res = []\n    for index, row in dataframe.iterrows():\n        if row[\"Venue Category\"] in (to_BAR_CLUB+ny_BAR_CLUB):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        1, 0, 0, 0, 0, 0, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_RESTAURANT+ny_RESTAURANT):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 1, 0, 0, 0, 0, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_SERVICES+ny_SERVICES):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 1, 0, 0, 0, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_LEISURE_SPORTS+ny_LEISURE_SPORTS):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 0, 1, 0, 0, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_CULTURAL_SCHOOLS+ny_CULTURAL_SCHOOLS):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 0, 0, 1, 0, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_PARKS_NATURE_RURAL+ny_PARKS_NATURE_RURAL):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 0, 0, 0, 1, 0, 0, 1])\n        elif row[\"Venue Category\"] in (to_TRANSPORT_INFRASTRUCTURE+ny_TRANSPORT_INFRASTRUCTURE):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 0, 0, 0, 0, 1, 0, 1])\n        elif row[\"Venue Category\"] in (to_RESIDENTIAL+ny_RESIDENTIAL):\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 0, 0, 0, 0, 0, 1, 1])\n        else:\n            res.append([row[\"Neighborhood\"], row[\"Neighborhood Latitude\"], row[\"Neighborhood Longitude\"],\n                        row[\"Venue Latitude\"], row[\"Venue Longitude\"],\n                        0, 0, 1, 0, 0, 0, 0, 0, 1])\n    return res\n\n#Neighborhood\n#Neighborhood Latitude\n#Neighborhood Longitude\n#Venue\n#Venue Latitude\n#Venue Longitude\n#Venue Category"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Create encoded venues dataframe\nto_encoded_venues = pd.DataFrame(encode_venues_categories(to_venues), \n                                 columns=[\"Neighborhood\", \"Neighborhood Latitude\", \"Neighborhood Longitude\", \n                                          \"Venue Latitude\", \"Venue Longitude\", \n                                          \"Bars and Clubs\", \"Restaurants\", \"Services\", \"Leisure and Sports\",\n                                          \"Education and Culture\", \"Nature and Parks\", \"Transportation\",\n                                          \"Residential\", \"Total Venues\"])\n\n\n# Create encoded grouped venues dataframe\nto_encoded_grouped_venues = to_encoded_venues.groupby(['Neighborhood', \n                                                       'Neighborhood Latitude', \n                                                       'Neighborhood Longitude']).sum().sort_values(by=['Total Venues']).reset_index()\n# Save Neighborhood column for later\nto_encoded_grouped_venues_Neighborhood = to_encoded_grouped_venues['Neighborhood']\n# Drop non-integer columns\nto_encoded_grouped_venues = to_encoded_grouped_venues.drop(['Neighborhood Latitude', \n                                                            'Neighborhood Longitude',\n                                                            'Venue Latitude',\n                                                            'Venue Longitude',\n                                                            'Neighborhood'], axis=1)\n\n# Prepare encoded grouped venues dataframe for KMeans clustering\nto_encoded_grouped_venues_std = to_encoded_venues.groupby(['Neighborhood', \n                                                           'Neighborhood Latitude', \n                                                           'Neighborhood Longitude']).mean().sort_values(by=['Total Venues']).reset_index()\n# Save columns for later\nto_encoded_grouped_venues_std_Neighborhood = to_encoded_grouped_venues_std['Neighborhood']\nto_encoded_grouped_venues_std_Latitude = to_encoded_grouped_venues_std['Neighborhood Latitude']\nto_encoded_grouped_venues_std_Longitude = to_encoded_grouped_venues_std['Neighborhood Longitude']\n# Drop non-integer columns\nto_encoded_grouped_venues_std = to_encoded_grouped_venues_std.drop(['Neighborhood Latitude', \n                                                                    'Neighborhood Longitude',\n                                                                    'Venue Latitude',\n                                                                    'Venue Longitude',\n                                                                    'Neighborhood',\n                                                                    'Total Venues'], axis=1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_encoded_venues.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_encoded_grouped_venues.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_encoded_grouped_venues_std.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Create encoded venues dataframe\nny_encoded_venues = pd.DataFrame(encode_venues_categories(ny_venues), \n                                 columns=[\"Neighborhood\", \"Neighborhood Latitude\", \"Neighborhood Longitude\", \n                                          \"Venue Latitude\", \"Venue Longitude\", \n                                          \"Bars and Clubs\", \"Restaurants\", \"Services\", \"Leisure and Sports\",\n                                          \"Education and Culture\", \"Nature and Parks\", \"Transportation\",\n                                          \"Residential\", \"Total Venues\"])\n\n# Create encoded grouped venues dataframe\nny_encoded_grouped_venues = ny_encoded_venues.groupby(['Neighborhood', \n                                                       'Neighborhood Latitude', \n                                                       'Neighborhood Longitude']).sum().sort_values(by=['Total Venues']).reset_index()\n\n# Save Neighborhood column for later\nny_encoded_grouped_venues_Neighborhood = ny_encoded_grouped_venues['Neighborhood']\n# Drop non-integer columns\nny_encoded_grouped_venues = ny_encoded_grouped_venues.drop(['Neighborhood Latitude', \n                                                            'Neighborhood Longitude',\n                                                            'Venue Latitude',\n                                                            'Venue Longitude',\n                                                            'Neighborhood'], axis=1)\n\n# Prepare encoded grouped venues dataframe for KMeans clustering\nny_encoded_grouped_venues_std = ny_encoded_venues.groupby(['Neighborhood', \n                                                           'Neighborhood Latitude', \n                                                           'Neighborhood Longitude']).mean().sort_values(by=['Total Venues']).reset_index()\n# Save Neighborhood column for later\nny_encoded_grouped_venues_std_Neighborhood = ny_encoded_grouped_venues_std['Neighborhood']\nny_encoded_grouped_venues_std_Latitude = ny_encoded_grouped_venues_std['Neighborhood Latitude']\nny_encoded_grouped_venues_std_Longitude = ny_encoded_grouped_venues_std['Neighborhood Longitude']\n# Drop non-integer columns\nny_encoded_grouped_venues_std = ny_encoded_grouped_venues_std.drop(['Neighborhood Latitude', \n                                                                    'Neighborhood Longitude',\n                                                                    'Venue Latitude',\n                                                                    'Venue Longitude',\n                                                                    'Neighborhood',\n                                                                    'Total Venues'], axis=1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_encoded_venues.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_encoded_grouped_venues.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_encoded_grouped_venues_std.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')\n\nseries = to_encoded_venues['Neighborhood'].value_counts()#[:20]\nseries.head(3)\n\nseries.iplot(kind='bar', yTitle='Number of Venues', xTitle=None, title='Toronto numbers of venues per neighborhood',\n             filename='toronto-bar-chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "group_labels = ['Toronto Distplot']\nfig = ff.create_distplot([np.array(to_encoded_grouped_venues['Total Venues'].tolist())], group_labels )\npy.plotly.iplot(fig, filename='Basic Distplot')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')\n\nseries = ny_encoded_venues['Neighborhood'].value_counts()#[:20]\nseries.head(3)\n\nseries.iplot(kind='bar', yTitle='Number of Venues', xTitle=None, title='New York City numbers of venues per neighborhood',\n             filename='newyork-bar-chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "group_labels = ['New York Distplot']\nfig = ff.create_distplot([np.array(ny_encoded_grouped_venues['Total Venues'].tolist())], group_labels )\npy.plotly.iplot(fig, filename='Basic Distplot')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')\n\nseries = to_encoded_grouped_venues['Restaurants'].value_counts()\nseries.head(3)\n\nseries.iplot(kind='bar', xTitle='Number of Restaurants', yTitle='Number of Neighborhoods', \n             title='Number of Neighborhoods with X number of Restaurants in Toronto',\n             filename='toronto_rest-bar-chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "group_labels = ['Toronto Distplot']\nfig = ff.create_distplot([np.array(to_encoded_grouped_venues['Restaurants'].tolist())], group_labels )\npy.plotly.iplot(fig, filename='Basic Distplot')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')\n\nseries = ny_encoded_grouped_venues['Restaurants'].value_counts()\nseries.head(3)\n\nseries.iplot(kind='bar', xTitle='Number of Restaurants', yTitle='Number of Neighborhoods', \n             title='Number of Neighborhoods with X number of Restaurants in New York City',\n             filename='newyork_rest-bar-chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "group_labels = ['New York Distplot']\nfig = ff.create_distplot([np.array(ny_encoded_grouped_venues['Restaurants'].tolist())], group_labels )\npy.plotly.iplot(fig, filename='Basic Distplot')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add histogram data\nx1 = np.array(to_encoded_grouped_venues['Restaurants'].tolist())\nx2 = np.array(ny_encoded_grouped_venues['Restaurants'].tolist())\n\n# Group data together\nhist_data = [x1, x2]\n\ngroup_labels = ['Toronto', 'NYC']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels)\n\n# Plot!\npy.plotly.iplot(fig, filename='Distplot with Multiple Datasets')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add histogram data\nx1 = np.array(to_encoded_grouped_venues['Bars and Clubs'].tolist())\nx2 = np.array(ny_encoded_grouped_venues['Bars and Clubs'].tolist())\n\n# Group data together\nhist_data = [x1, x2]\n\ngroup_labels = ['Toronto', 'NYC']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels)\n\n# Plot!\npy.plotly.iplot(fig, filename='Distplot with Multiple Datasets')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add histogram data\nx1 = np.array(to_encoded_grouped_venues['Services'].tolist())\nx2 = np.array(ny_encoded_grouped_venues['Services'].tolist())\n\n# Group data together\nhist_data = [x1, x2]\n\ngroup_labels = ['Toronto', 'NYC']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels)\n\n# Plot!\npy.plotly.iplot(fig, filename='Distplot with Multiple Datasets')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Copy the encoded grouped venues standarized dataframe\nny_clustered_neighborhoods = ny_encoded_grouped_venues_std\n\n# Columns list\nclmns = [\"Bars and Clubs\", \"Restaurants\", \"Services\", \"Leisure and Sports\",\n         \"Education and Culture\", \"Nature and Parks\", \"Transportation\", \"Residential\"]\n    \n# Cluster the data\nkmeans = KMeans(n_clusters=5, random_state=0).fit(ny_clustered_neighborhoods)\nlabels = kmeans.labels_\n\n# Make the new Cluster column\nny_clustered_neighborhoods['Cluster'] = labels\n\n# Add the column into our list\nclmns.extend(['Cluster'])\n\n# Lets analyze the clusters\nny_pie_clusters = ny_clustered_neighborhoods[clmns].groupby(['Cluster']).mean()\nny_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_pie_clusters.columns = [0,1,2,3,4,5,6,7]\nny_pie_clusters = ny_pie_clusters.T\nny_pie_clusters.columns = ['results_0', 'results_1', 'results_2', 'results_3', 'results_4']\nny_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "llabels = np.array(['Bars and Clubs', 'Restaurants', 'Services', 'Leisure and Sports',\n                    'Education and Culture', 'Nature and Parks', 'Transportation', 'Residential'])\ncolors = np.array(['#d5f4e6', '#80ced6', '#618685', '#ffef96', '#50394c', '#b2b2b2', '#f4e1d2', '#fefbd8'])\nny_pie_clusters['labels'] = llabels\nny_pie_clusters['colors'] = colors\nny_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=ny_pie_clusters['labels'], \n               values=ny_pie_clusters['results_0'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=ny_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=ny_pie_clusters['labels'], \n               values=ny_pie_clusters['results_1'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=ny_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=ny_pie_clusters['labels'], \n               values=ny_pie_clusters['results_2'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=ny_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=ny_pie_clusters['labels'], \n               values=ny_pie_clusters['results_3'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=ny_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=ny_pie_clusters['labels'], \n               values=ny_pie_clusters['results_4'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=ny_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Copy the encoded grouped venues standarized dataframe\nto_clustered_neighborhoods = to_encoded_grouped_venues_std\n\n# Columns list\nclmns = [\"Bars and Clubs\", \"Restaurants\", \"Services\", \"Leisure and Sports\",\n         \"Education and Culture\", \"Nature and Parks\", \"Transportation\", \"Residential\"]\n    \n# Cluster the data\nkmeans = KMeans(n_clusters=5, random_state=0).fit(to_clustered_neighborhoods)\nlabels = kmeans.labels_\n\n# Make the new Cluster column\nto_clustered_neighborhoods['Cluster'] = labels\n\n# Add the column into our list\nclmns.extend(['Cluster'])\n\n# Lets analyze the clusters\nto_pie_clusters = to_clustered_neighborhoods[clmns].groupby(['Cluster']).mean()\nto_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_pie_clusters.columns = [0,1,2,3,4,5,6,7]\nto_pie_clusters = to_pie_clusters.T\nto_pie_clusters.columns = ['results_0', 'results_1', 'results_2', 'results_3', 'results_4']\nto_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "llabels = np.array(['Bars and Clubs', 'Restaurants', 'Services', 'Leisure and Sports',\n                    'Education and Culture', 'Nature and Parks', 'Transportation', 'Residential'])\ncolors = np.array(['#92a8d1', '#034f84', '#f7cac9', '#f7786b', '#deeaee', '#b1cbbb', '#eea29a', '#c94c4c'])\nto_pie_clusters['labels'] = llabels\nto_pie_clusters['colors'] = colors\nto_pie_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=to_pie_clusters['labels'], \n               values=to_pie_clusters['results_0'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=to_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=to_pie_clusters['labels'], \n               values=to_pie_clusters['results_1'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=to_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=to_pie_clusters['labels'], \n               values=to_pie_clusters['results_2'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=to_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=to_pie_clusters['labels'], \n               values=to_pie_clusters['results_3'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=to_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trace = go.Pie(labels=to_pie_clusters['labels'], \n               values=to_pie_clusters['results_4'], \n               hoverinfo='label+percent', \n               textfont=dict(size=20),\n               marker=dict(colors=to_pie_clusters['colors']))\npy.plotly.iplot([trace], filename='basic_pie_chart')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set color scheme for the clusters\nny_rainbow = ['#ffef96', '#d5f4e6', '#b2b2b2', '#618685', '#80ced6']\nto_rainbow = ['#92a8d1', '#034f84', '#f7cac9', '#b1cbbb', '#c94c4c']\n\ndef generate_map_of_city_clustered_neighborhoods(city_name, city_neighborhoods, kclusters, rainbow):\n    \n    # Find city geographical coordinates using geocode google API\n    geolocator = Nominatim(user_agent=\"my_jupyter_notebook\")\n    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n    city_location = geolocator.geocode(city_name) #'New York City, NY'\n    city_latitude = city_location.latitude\n    city_longitude = city_location.longitude\n    print('The geographical coordinates of \"{}\" are {}, {}.'.format(city_name, city_latitude, city_longitude))\n    \n    # Check number of Boroughs and Neighborhoods in the collected Dataset\n    print('The \"{}\" dataframe has {} clusters and {} neighborhoods.'.format(\n          city_name,\n          kclusters,\n          len(city_neighborhoods['Neighborhood'].unique())))\n    \n    # create map of city using latitude and longitude values\n    map_city = folium.Map(location=[city_latitude, city_longitude], zoom_start=10)\n\n    # add markers to map\n    for lat, lng, neighborhood, cluster in zip(city_neighborhoods['Neighborhood Latitude'], \n                                               city_neighborhoods['Neighborhood Longitude'], \n                                               city_neighborhoods['Neighborhood'], \n                                               city_neighborhoods['Cluster']):\n        label = folium.Popup(str(neighborhood)+', Cluster: '+str(cluster), parse_html=True)\n        folium.CircleMarker(\n            [lat, lng],\n            radius=5,\n            popup=label,\n            color=rainbow[cluster-1],\n            fill=True,\n            fill_color=rainbow[cluster-1],\n            fill_opacity=0.7).add_to(map_city)  \n\n    return map_city"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add the neighborhoods columns back to the clustered dataframe\nny_clustered_neighborhoods['Neighborhood'] = ny_encoded_grouped_venues_std_Neighborhood\nny_clustered_neighborhoods['Neighborhood Latitude'] = ny_encoded_grouped_venues_std_Latitude\nny_clustered_neighborhoods['Neighborhood Longitude'] = ny_encoded_grouped_venues_std_Longitude\n\n# Drop the venues columns from the clustered dataframe\nny_clustered_neighborhoods = ny_clustered_neighborhoods.drop([\"Bars and Clubs\", \n                                                              \"Restaurants\", \n                                                              \"Services\", \n                                                              \"Leisure and Sports\",\n                                                              \"Education and Culture\", \n                                                              \"Nature and Parks\", \n                                                              \"Transportation\", \n                                                              \"Residential\"], axis=1)\nny_clustered_neighborhoods.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_clustered_neighborhoods('New York City, NY', ny_clustered_neighborhoods, 5, ny_rainbow)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add the neighborhoods columns back to the clustered dataframe\nto_clustered_neighborhoods['Neighborhood'] = to_encoded_grouped_venues_std_Neighborhood\nto_clustered_neighborhoods['Neighborhood Latitude'] = to_encoded_grouped_venues_std_Latitude\nto_clustered_neighborhoods['Neighborhood Longitude'] = to_encoded_grouped_venues_std_Longitude\n\n# Drop the venues columns from the clustered dataframe\nto_clustered_neighborhoods = to_clustered_neighborhoods.drop([\"Bars and Clubs\", \n                                                              \"Restaurants\", \n                                                              \"Services\", \n                                                              \"Leisure and Sports\",\n                                                              \"Education and Culture\", \n                                                              \"Nature and Parks\", \n                                                              \"Transportation\", \n                                                              \"Residential\"], axis=1)\nto_clustered_neighborhoods.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "generate_map_of_city_clustered_neighborhoods('Toronto, ON', to_clustered_neighborhoods, 5, to_rainbow)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_clustered_neighborhoods.loc[to_clustered_neighborhoods['Cluster'] == 4, to_clustered_neighborhoods.columns[[1] + list(range(2, to_clustered_neighborhoods.shape[1]))]].Neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "to_clustered_neighborhoods.loc[to_clustered_neighborhoods['Cluster'] == 3, to_clustered_neighborhoods.columns[[1] + list(range(2, to_clustered_neighborhoods.shape[1]))]].Neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_clustered_neighborhoods.loc[(ny_clustered_neighborhoods['Cluster'] == 4)].Neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ny_clustered_neighborhoods.loc[(ny_clustered_neighborhoods['Cluster'] == 0)].Neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}